[{"title":"Strange bedfellows: how a web-tier validation framework enables strongly typed, big data pipelines","description":"<p>The other day I was talking with a colleague about data validation and the <a href=\"http://www.playframework.com/\">Play web framework</a> came up.  Play has a nice API for validating HTML form and JSON submissions.  This works great when you’re processing small amounts of data from the web-tier of your application.  But could that same tech benefit a Big Data team working on a backend powered by Hadoop or <a href=\"https://spark.apache.org/\">Spark</a>?</p>\n\n<p>We decided to find out and the results were encouraging.  The secret sauce?  <a href=\"https://www.playframework.com/documentation/2.3.x/ScalaJson\">Play’s combinator-based approach to data validation</a>.</p>\n\n<h2 id=\"whether-your-data-is-big-or-small-garbage-in-is-garbage-out\">Whether your data is big or small, garbage in is garbage out</h2>\n\n<p>MediaMath processes TBs of online user behavior and advertising data every day. It’s inevitable that with hundreds of machines spread across multiple datacenters, legacy systems and par","link":"http://themodernlife.net/scala/validation/play/spark/2014/08/07/serlialization-validation-in-play-and-spark/","owner":"Ian Hummel"}]