[{"title":"How to Setup a Scheduled Scala Spark Job","description":"<p>Have you written a Scala Spark job that processes a massive amount of data on an intimidating amount of RAM and you want to run it daily/weekly/monthly on a schedule on <a href=\"https://aws.amazon.com\">AWS</a>?\nI had to do this recently, and couldnâ€™t find a good tutorial on the full process to get the spark job running.\nIncluded in this article and accompanying repository is everything you need to get your Scala Spark job running on AWS <a href=\"https://aws.amazon.com/datapipeline/\">Data Pipeline</a> and <a href=\"https://aws.amazon.com/emr/\">EMR</a>.</p>\n\n<h2 id=\"code-repo\">Code Repo</h2>\n\n<p>This tutorial is not going to walk you through the process of actually writing your specific Scala Spark job to do whatever number crunching you need. \nThere are already plenty of resources available (<a href=\"https://www.analyticsvidhya.com/blog/2017/01/scala/\">1</a>, <a href=\"https://spark.apache.org/docs/latest/quick-start.html\">2</a>, <a href=\"https://www.coursera.org/learn/scala-spark-big-","link":"http://engineering.curalate.com/2019/03/27/scheduled-scala-spark-job.html","owner":"CSC - IT Center For Science - Cloud Team"}]