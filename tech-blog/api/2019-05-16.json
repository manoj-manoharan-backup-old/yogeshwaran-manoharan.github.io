[{"title":"\nThe struggles of an open source maintainer\n","description":"Months ago the maintainer of an OSS project in the sphere of system software, with quite a big and active community, wrote me an email saying that he struggles to continue maintaining his project after so many years, because of how much psychologically taxing such effort is. He was looking for advices from me, I’m not sure to be in the position of giving advices, however I told him I would write a blog post about what I think about the matter. Several weeks passed, and multiple times I started writing such post and stopped, because I didn’t had the time to process the ideas for enough time. Now I think I was able to analyze myself to find answers inside my own weakness, struggles, and desire of freedom, that inevitably invades the human minds when they do some task, that also has some negative aspect, for a prolonged amount of time. Maintaining an open source project is also a lot of joy and fun and these latest ten years of my professional life are surely memorable, even if not the ab","link":"\nhttp://antirez.com/news/129\n","owner":"Andrey Akinshin"},{"title":"4 Challenges When Migrating to a Cloud-Native RDBMS","description":"As organizations migrate to the cloud, they need a cloud-native, relational database to help them move all their applications to this new environment.\nOver the last ten years, the infrastructure that runs our applications has fundamentally changed. As we move to the cloud, we now have to think about managing workloads in an environment where we don&#x2019;t have tight control over the infrastructure that hosts our applications. Things like &#x201C;how can I recover my data?","link":"https://www.cockroachlabs.com/blog/cloud-native-relational-database-management/","owner":"Cloudflare"},{"title":"How to remove duplicate lines from files preserving their order","description":"<p>Suppose you have a text file and you need to remove all of its duplicate lines.</p>\n\n<h2 id=\"tldr\">TL;DR</h2>\n\n<p>To remove the duplicate lines <strong>preserving their order in the file</strong> use:</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">awk</span> <span class=\"s1\">'!visited[$0]++'</span> your_file <span class=\"o\">&gt;</span> deduplicated_file\n</code></pre></div></div>\n\n<h2 id=\"how-it-works\">How it works</h2>\n\n<p>The script keeps an associative array with <em>indices</em> equal to the unique lines of the file and <em>values</em> equal to their occurrences. For each line of the file, if the line occurrences are zero then it increases them by one and <strong>prints the line</strong>, otherwise it just increases the occurrences <strong>without printing the line</strong>.</p>\n\n<p>I was not familiar with <code class=\"highlighter-rouge\">awk</code> and I wanted to understand how is this accomplished with such","link":"https://iridakos.com/programming/2019/05/16/remove-duplicate-lines-preserving-order-linux","owner":"Larry Land"}]